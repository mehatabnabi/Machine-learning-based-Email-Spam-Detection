{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email Spam Detection Report\n",
    "\n",
    "#### Note: Below is the report, followed by the code.\n",
    "\n",
    "### Abstract\n",
    "\n",
    "In this paper, we build a spam detector using 4 Machine Learning models and evaluate them with test data using different performance metrics used. The dataset we used was from a shuffled sample of email subjects and bodies containing both spam and ham emails in different proportions, which we converted into lemmas. As per our analysis, Naive Bayes model and Random Forest models worked well for spam detection, whereas SVM performed the poorest among the 4 models.\n",
    "\n",
    "\n",
    "### Methodology\n",
    "#### Introduction\n",
    "\n",
    "Email has become one of the most important forms of communication. In 2014, there are estimated to be 4.1 billion email accounts worldwide, and about 196 billion emails are sent each day worldwide. Spam is one of the major threats posed to email users. In 2013, 69.6% of all email flows were spam. Therefore, an effective spam filtering technology is a significant contribution to the sustainability of the cyberspace and to our society [1].\n",
    "\n",
    "To prepare the data, we followed the steps below:\n",
    "    1.\tDownload spam and ham emails through Google’s takeout service as an mbox file.\n",
    "    2.\tRead the mbox files into lists using the ‘mailbox’ package. Each element in the list contained an individual email. In the first iteration, we included 1000 ham mails and 400 spam mails (we tried different ratios after the first iteration).\n",
    "    3.\tUnpacked each email and concatenated their subject and body. We decided to include the email subject as well in our analysis because it is also a great indicator whether an email is a spam or ham.\n",
    "    4.\tConverted the lists to dataframes, joined the spam and ham dataframes and shuffled the resultant dataframe.\n",
    "    5.\tSplit the dataframe into train and test dataframes. The test data was 33% of the original dataset.\n",
    "    6.\tSplit the mail text into lemmas and applied TF-IDF transformation using CountVectorizer followed by TF-IDF transformer.\n",
    "    7.\tTrained four models using the training data:\n",
    "        a.\tNaive Bayes\n",
    "        b.\tDecision Tree\n",
    "        c.\tSVM\n",
    "        d.\tRandom Forest\n",
    "\n",
    "    8.\tUsing the trained models, predicted the email label for test dataset. Calculated four metrics to gauge performance of the models:\n",
    "        a.\tAccuracy\n",
    "        b.\tPrecision\n",
    "        c.\tRecall\n",
    "        d.\tF-score\n",
    "        e.\tAUC\n",
    "\n",
    "\n",
    "### ML Models Employed\n",
    "Email spam detection is a classification problem. Some algorithms like Naive Bayes Classifier, Decision Trees work well for spam detection. Algorithms like KNN, Linear Regression don’t really work well due to inherent disadvantages such as curse of dimensionality.\n",
    "\n",
    "#### A.\tNaive Bayes with bag of words approach using TF-IDF\n",
    "\n",
    "Naive Bayes is the easiest classification algorithm (fast to build, regularly used for spam detection).  It is a popular (baseline) method for text categorization, the problem of judging documents as belonging to one category or the other (such as spam or legitimate, sports or politics, etc.) with word frequencies as the features.\n",
    "\n",
    "Why use Naive Bayes?\n",
    "1.\tNB is very simple, easy to implement and fast because essentially you’re just doing a bunch of counts.\n",
    "2.\tIf the NB conditional independence assumption holds, then it will converge quicker than discriminative models like logistic regression.\n",
    "3.\tNB needs works well even with less sample data.\n",
    "4.\tNB is highly scalable. It scales linearly with the number of predictors and data points.\n",
    "5.\tNB can be used for both binary and multi-class classification problems and handles continuous and discrete data [2].\n",
    "6.\tNB is not sensitive to irrelevant features.\n",
    "\n",
    "Feature extraction using BOW : TF-IDF\n",
    "\n",
    "Term frequency-Inverse document frequency uses all the tokens in the dataset as vocabulary.Frequency of occurrence of a token from vocabulary in each document consists of the term frequency and number of documents in which token occurs determines the Inverse document frequency.What this ensures is that,if a token occurs frequently in a document that token will have high TF but if that token occurs frequently in majority of documents then it reduces the IDF ,so stop words like an,the,i which occur frequently are penalized and important words which contain the essence of document get a boost.Both these TF and IDF matrices for a particular document are multiplied and normalized to form TF-IDF of a document [3].\n",
    " \n",
    "TF-IDF Transformation\n",
    "\n",
    "#### B.  Decision Trees\n",
    "Decision trees are used for classification and regression. In decision analysis, a decision tree can be used to visually and explicitly represent decisions and decision making. The decision of making strategic splits heavily affects a tree’s accuracy. The decision criteria is different for classification and regression trees. Information theory is a measure to define this degree of disorganization in a system known as Entropy. If the sample is completely homogeneous, then the entropy is zero and if the sample is an equally divided (50% – 50%), it has entropy of one. It chooses the split which has lowest entropy compared to parent node and other splits. The lesser the entropy, the better it is.\n",
    "\n",
    "Why use Decision Trees?\n",
    "1.\tDecision trees implicitly perform variable screening or feature selection. When we fit a decision tree to a training dataset, the top few nodes on which the tree is split are essentially the most important variables within the dataset and feature selection is completed automatically\n",
    "2.\tDecision trees are easy to understand, easy to represent visually and easy to communicate.\n",
    "3.\tNonlinear relationships between parameters do not affect tree performance. Also trees can explain the non-linearity in an intuitive manner.\n",
    "\n",
    "#### C.  Support Vector Machine (SVM)\n",
    "\n",
    "SVM is a supervised machine learning algorithm which can be used for both classification or regression challenges. However,  it is mostly used in classification problems. In this algorithm, we plot each data item as a point in n-dimensional space (where n is number of features you have) with the value of each feature being the value of a particular coordinate. Then, we perform classification by finding the hyperplane that differentiate the two classes very well [4]. Support Vectors are simply the coordinates of individual observation. Support Vector Machine is a frontier which best segregates the two classes (hyper-plane/ line). If the data requires non-linear classification, SVM can employe Kernels, which are functions which takes low dimensional input space and transform it to a higher dimensional space i.e. they convert non separable problem to separable problem.\n",
    "\n",
    "#### D.  Random Forest\n",
    "Random forest is like bootstrapping algorithm with Decision tree (CART) model. Random forest tries to build multiple CART model with different sample and different initial variables. For instance, it will take a random sample of 100 observation and 5 randomly chosen initial variables to build a CART model. It will repeat the process (say) 10 times and then make a final prediction on each observation. Final prediction is a function of each prediction. This final prediction can simply be the mean of each prediction[4]. \n",
    "Random forest gives much more accurate predictions when compared to simple CART/CHAID or regression models in many scenarios. These cases generally have high number of predictive variables and huge sample size. This is because it captures the variance of several input variables at the same time and enables high number of observations to participate in the prediction.\n",
    "Metrics Used\n",
    "\n",
    "Following are the metrics we used to evaluate the performance of ML techniques:\n",
    "##### 1.\tPrecision\n",
    "Precision refers to the closeness of two or more measurements to each other. In Machine Learning, precision is the fraction of relevant instances among the retrieved instances.\n",
    "Precision = TP / (TP + FP)\n",
    "(Where TP = True Positive, TN = True Negative, FP = False Positive, FN = False Negative).\n",
    "\n",
    "##### 2.\tAccuracy\n",
    "Accuracy refers to the closeness of a measured value to a standard or known value.\n",
    "Accuracy = (TP+TN) / ALL\n",
    "\n",
    "##### 3.\tRecall\n",
    "Recall is how many of the true positives were recalled (found), i.e. how many of the correct hits were also found.\n",
    "Recall = TP / (TP + FN)\n",
    "##### 4.\tF-Score\n",
    "F-scores are a statistical method for determining accuracy accounting for both precision and recall. It is essentially the harmonic mean of precision and recall.\n",
    " \n",
    "##### 5.\tAUC\n",
    "AUC is the area under the ROC curve. The closer the AUC value is to 1, the better the model.\n",
    "\n",
    "\n",
    "### Comparison of Performance of the Models\n",
    "\n",
    "#### 1.\tNaive Bayes\n",
    "For this problem, Naive Bayes algorithm worked well as expected. Following were the confusion matrix and scores:\n",
    "\n",
    " \n",
    "                                                    [199   3]\n",
    "\n",
    "                                                     [ 78  45]\n",
    "\t\n",
    "                                                    Precision\t0.75, \n",
    "\n",
    "                                                    Accuracy\t0.94, \n",
    "\n",
    "                                                    Recall\t0.37, \n",
    "\n",
    "                                                    F-Score\t0.53, \n",
    "\n",
    "                                                    AUC\t0.67\n",
    "\n",
    "High accuracy suggests that the model is very good at correctly classifying the mails as ham or spam. Precision value is also good at 0.75, means the model has a low false positive rate. This can be corroborated by looking at false positives found - only 3. The model has a lower recall value compared to Decision Tree and Random Forest models. This indicates that results are complete to a large extent. In other words, probability of detection is lower compared to Decision Tree and Random Forest. Together, having a high precision and low recall means that the most of ham predictions are correct, but the model is not predicting all the ham in the test data. The AUC value is good too, as expected.\n",
    "\n",
    "#### 2.\tDecision Tree\n",
    "\n",
    " \n",
    "                                                    [152  50]\n",
    "\n",
    "                                                     [ 44  79]\n",
    "\n",
    "                                                    Precision\t0.71\n",
    "\n",
    "                                                    Accuracy\t0.61\n",
    "\n",
    "                                                    Recall\t0.64\n",
    "\n",
    "                                                    F-Score\t0.62\n",
    "\n",
    "                                                    AUC\t0.64\n",
    "\n",
    "Accuracy and Precision of the decision tree is low compared to Naive Bayes model. However, it has a higher Recall and F-Score. Good recall of 0.63 means predictions of decision tree are more complete compared to Naive Bayes. Good precision of 0.71 indicates that model has low false positive rate. Since the dataset has an uneven distribution of ham and spam, F-Score becomes an important metric. F-Score of 0.62 indicates a fairly good model in terms of precision and recall both. The AUC score is good, although not as good as NB.\n",
    "\n",
    "#### 3.\tSVM\n",
    "\n",
    " \n",
    "                                                        [202   0]\n",
    "\n",
    "                                                         [123   0]\n",
    "\n",
    "                                                        Precision\t0.62\n",
    "\n",
    "                                                        Accuracy\t0\n",
    "\n",
    "                                                        Recall\t0\n",
    "\n",
    "                                                        F-Score\t0\n",
    "\n",
    "                                                        AUC\t0.5\n",
    "\n",
    "It seems like SVM is unable to predict positive class at all. When there is no predicted sample, it means that TP+FP is 0. Hence precision and F-score are not defined and marked as 0. Accuracy is also 0 since true positive (numerator) is 0. SVM has high true negative rate, but a high false negative rate as well. The AUC score is the worst too.\n",
    "\n",
    "#### 4.\tRandom Forest\n",
    "\n",
    " \n",
    "                                                        [176  26]\n",
    "\n",
    "                                                         [ 44  79]\n",
    "\n",
    "                                                        Precision\t0.78\n",
    "\n",
    "                                                        Accuracy\t0.75\n",
    "\n",
    "                                                        Recall\t0.64\n",
    "\n",
    "                                                        F-Score\t0.69\n",
    "\n",
    "                                                        AUC\t0.73\n",
    "\n",
    "\n",
    "Random Forest algorithm had a high precision and accuracy. Considering lower accuracy as compared to Naive Bayes, good precision value indicates low false positive rate. Recall value is also good, especially when compared to Naive Bayes. Having high precision and recall suggests that the model is correctly predicting positive class (ham) and also capturing most ham in the test data. It follows that the model also has a good F-score, since it is directly proportional to Precision and Accuracy. The AUC score is the best too amongst all the models.\n",
    "\n",
    "### Results\n",
    "\n",
    "It is clear from the comparison that SVM model did not work out very well to solve our problem of spam detection. Naive Bayes and Random Forest both work pretty well. While Naive Bayes algorithm is has a high accuracy and a good precision, the recall value is poorer compared to Decision Tree and Random Forest. Since SVM model could not predict any positive values at all, its accuracy, recall and F-score were 0. As far as the F-score is concerned, Decision Tree and Random Forest have a good score as a result of good precision and recall both. NB and Random forest had the best AUC scores. Overall, we think that both Naive Bayes and Random Forest will be very good for spam detection. Of course, we can employ boosting or stacking ensemble methods to combine two or more of these models into a really good spam detector.\n",
    "\n",
    "### References\n",
    "\n",
    "1.\tEmail spam detection using Machine Learning (May, 2014). Retrieved from https://ese.wustl.edu/ContentFiles/Research/UndergraduateResearch/CompletedProjects/WebPages/sp14/SongSteimle/WebPage/motivation.html\n",
    "2.\tWhat are the advantages of using a naive Bayes for classification? Quora. Retrieved from https://www.quora.com/What-are-the-advantages-of-using-a-naive-Bayes-for-classification\n",
    "3.\tDocument feature extraction and classification. Ishaan Arora (March 2017). Retrieved from https://towardsdatascience.com/document-feature-extraction-and-classification-53f0e813d2d3\n",
    "4.\tUnderstanding Support Vector Machine algorithm from examples, Analytics Vidhya. Sunil Ray (September, 2017). Retrieved from https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nissi\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\nissi\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\nissi\\Anaconda3\\lib\\site-packages\\sklearn\\learning_curve.py:23: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#import all the needed libraries\n",
    "import mailbox\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from textblob import TextBlob\n",
    "import pandas\n",
    "import sklearn\n",
    "#import cPickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.learning_curve import learning_curve\n",
    "\n",
    "#import metrics libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to get email text from email body\n",
    "def getmailtext(message): #getting plain text 'email body'\n",
    "    body = None\n",
    "    #check if mbox email message has multiple parts\n",
    "    if message.is_multipart():\n",
    "        for part in message.walk():\n",
    "            if part.is_multipart():\n",
    "                for subpart in part.walk():\n",
    "                    if subpart.get_content_type() == 'text/plain':\n",
    "                        body = subpart.get_payload(decode=True)\n",
    "            elif part.get_content_type() == 'text/plain':\n",
    "                body = part.get_payload(decode=True)\n",
    "    #if message only has a single part            \n",
    "    elif message.get_content_type() == 'text/plain':\n",
    "        body = message.get_payload(decode=True)\n",
    "    #return mail text which concatenates both mail subject and body\n",
    "    mailtext=str(message['subject'])+\" \"+str(body)\n",
    "    return mailtext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read spam mbox email file\n",
    "mbox = mailbox.mbox('Spam.mbox')\n",
    "\n",
    "mlist_spam = []\n",
    "#create list which contains mail text for each spam email message\n",
    "for message in mbox:\n",
    "    mlist_spam.append(getmailtext(message))\n",
    "    #break\n",
    "#read ham mbox email file\n",
    "mbox_ham = mailbox.mbox('ham.mbox')\n",
    "\n",
    "mlist_ham = []\n",
    "count=0\n",
    "#create list which contains mail text for each ham email message\n",
    "for message in mbox_ham:\n",
    "    \n",
    "    mlist_ham.append(getmailtext(message))\n",
    "    if count>601:\n",
    "        break\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             message label  length\n",
      "0  Uninterrupted High Speed Connectivity b'View I...  spam     250\n",
      "1  Opening For Experienced Java Engineer At GENPA...  spam      66\n",
      "2  Opportunities in Mumbai for Php Developer, Php...  spam      59\n",
      "3  =?UTF-8?B?IDEwJSBkaXNjb3VudCB3aGVuIHlvdSBidXkg...  spam    2281\n",
      "4  Build to outlast b'View In New Tab\\nTo Remove ...  spam     226\n",
      "                                             message label  length\n",
      "0  Get rewarded on all your spends with the Plati...   ham     238\n",
      "1  New apartments were just posted near Seattle f...   ham      63\n",
      "2  =?UTF-8?Q?Your_Career_in_Machine_Learning_Star...   ham   17774\n",
      "3  Dear Customer, Better Body = Better Life b' \\n...   ham     992\n",
      "4  Top Deals Revealed : Great Indian Sale | Only ...   ham      70\n"
     ]
    }
   ],
   "source": [
    "#create 2 dataframes for ham spam mails which contain the following info-\n",
    "#Mail text, mail length, mail is ham/spam label\n",
    "import pandas as pd\n",
    "spam_df = pd.DataFrame(mlist_spam, columns=[\"message\"])\n",
    "spam_df[\"label\"] = \"spam\"\n",
    "\n",
    "spam_df['length'] = spam_df['message'].map(lambda text: len(text))\n",
    "print(spam_df.head())\n",
    "\n",
    "ham_df = pd.DataFrame(mlist_ham, columns=[\"message\"])\n",
    "ham_df[\"label\"] = \"ham\"\n",
    "\n",
    "ham_df['length'] = ham_df['message'].map(lambda text: len(text))\n",
    "print(ham_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge and shuffle dataframes for ham/spam mails\n",
    "mail_df = pd.concat([spam_df,ham_df])\n",
    "from sklearn.utils import shuffle\n",
    "mail_df = shuffle(mail_df)\n",
    "len(mail_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mail_train, mail_test, y_train, y_test = train_test_split(mail_df['message'],mail_df['label'],test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for each word in the email text, get the base form of the word and return the list of base words\n",
    "def split_into_lemmas(message):\n",
    "    message = message.lower()\n",
    "    words = TextBlob(message).words\n",
    "    # for each word, take its \"base form\" = lemma \n",
    "    return [word.lemma for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to apply the count vectorizer(BOW) and TF-IDF transforms to a set of input features\n",
    "def features_transform(mail):\n",
    "    #get the bag of words for the mail text\n",
    "    bow_transformer = CountVectorizer(analyzer=split_into_lemmas).fit(mail_train)\n",
    "    #print(len(bow_transformer.vocabulary_))\n",
    "    messages_bow = bow_transformer.transform(mail)\n",
    "    #print sparsity value\n",
    "    print('sparse matrix shape:', messages_bow.shape)\n",
    "    print('number of non-zeros:', messages_bow.nnz) \n",
    "    print('sparsity: %.2f%%' % (100.0 * messages_bow.nnz / (messages_bow.shape[0] * messages_bow.shape[1])))\n",
    "    #apply the TF-IDF transform to the output of BOW\n",
    "    tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "    messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
    "    #print(messages_tfidf.shape)\n",
    "    #return result of transforms\n",
    "    return messages_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (658, 10358)\n",
      "number of non-zeros: 36081\n",
      "sparsity: 0.53%\n"
     ]
    }
   ],
   "source": [
    "#transform training set features into a set of useful features to build models\n",
    "train_features=features_transform(mail_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function which takes in y test value and y predicted value and prints the associated model performance metrics\n",
    "def model_assessment(y_test,predicted_class):\n",
    "    print('confusion matrix')\n",
    "    print(confusion_matrix(y_test,predicted_class))\n",
    "    print('accuracy')\n",
    "    print(accuracy_score(y_test,predicted_class))\n",
    "    print('precision')\n",
    "    print(precision_score(y_test,predicted_class,pos_label='spam'))\n",
    "    print('recall')\n",
    "    print(recall_score(y_test,predicted_class,pos_label='spam'))\n",
    "    print('f-Score')\n",
    "    print(f1_score(y_test,predicted_class,pos_label='spam'))\n",
    "    print('AUC')\n",
    "    print(roc_auc_score(np.where(y_test=='spam',1,0),np.where(predicted_class=='spam',1,0)))\n",
    "    plt.matshow(confusion_matrix(y_test, predicted_class), cmap=plt.cm.binary, interpolation='nearest')\n",
    "    plt.title('confusion matrix')\n",
    "    plt.colorbar()\n",
    "    plt.ylabel('expected label')\n",
    "    plt.xlabel('predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create and fit NB model\n",
    "modelNB=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelNB.fit(train_features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (325, 10358)\n",
      "number of non-zeros: 13600\n",
      "sparsity: 0.40%\n"
     ]
    }
   ],
   "source": [
    "#transform test features to test the model performance\n",
    "test_features=features_transform(mail_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NB predictions\n",
    "predicted_class_NB=modelNB.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[199   3]\n",
      " [ 78  45]]\n",
      "accuracy\n",
      "0.750769230769\n",
      "precision\n",
      "0.9375\n",
      "recall\n",
      "0.365853658537\n",
      "f-Score\n",
      "0.526315789474\n",
      "AUC\n",
      "0.675501086694\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAD0CAYAAABuOhhTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAGLpJREFUeJzt3XuYXEWZx/Hvb4gYIKwCAQQkJEJE\n0YUYIl4AgV1UxAXU9UJECcIKrIKi666gPoDweNsVXa9g8AIoC4KgIiIQEcWgGMItiIAETCCACQGE\nGAKY+O4fp9p0xp6Z6p4+c/ry+zxPP9Pn0nXemcy8qVNVp0oRgZlZjoGqAzCz7uGEYWbZnDDMLJsT\nhpllc8Iws2xOGGaWzQnDzLI5YVRIhW9JelTSvFGUs6ekO9sZW1UkTZL0Z0nrVR2L/T154FZ1JO0J\nnAfsGBErq46nbJIWAf8WET+tOhZrjWsY1doOWNQPySKHpHFVxzDWJEUTr8urjtcJI5OkbSVdLOkh\nSQ9L+nLaPyDpY5IWS1om6RxJz0rHJqd/6FmS7pW0XNJH07EjgK8Dr0hV8I9LOkzS3EHXDUk7pPf7\nS/qdpBWS7pf0obR/b0lL6j7zQkk/l/QnSbdJOrDu2FmSviLpx6mc30jafojvuRb/uyTdl26djpb0\nUkkLUvlfrjt/e0k/Sz+f5ZLOlfTsdOzbwCTgR+n7/a+68o+QdC/ws7p94yRtKmmJpANSGRMkLZR0\n6Kj/QTuIpKwXMLHqWIkIv0Z4AesBtwCfBzYCxgN7pGOHAwuB5wETgIuBb6djk4EAzgQ2AHYBngJe\nmI4fBsytu84622lfADuk9w8Ce6b3mwDT0/u9gSXp/TNSPB8B1gf+CVhBcdsDcBbwCLAbMA44Fzh/\niO+7Fv8Z6Xt+DfAk8ANgC2AbYBmwVzp/B+DVwDOBzYFrgP+tK28RsG+D8s9JP9cN6vaNS+e8Bvhj\nut6ZwPeq/n1o8+9WDAwMZL2A+VXH6xpGnt2ArYH/jIiVEfFkRNRqAocAn4uIeyLiz8AJwMGDqtcf\nj4hVEXELReLZpcU4/gLsJOkfIuLRiLixwTkvp0hcn46IpyPiZ8ClwMy6cy6OiHkRsZoiYUwb4bqn\npu/5SmAlcF5ELIuI+4FfAi8BiIiFETEnIp6KiIeAzwF7ZXxfJ6ef66rBB9I1LwSuAl4PHJVRXldp\nooZROSeMPNsCi9Mf2GBbA4vrthdT/M+9Zd2+P9a9f4LiD7oV/wrsDyyW9AtJrxginvsi4q+DYtpm\nFPEsrXu/qsH2BABJW0g6P90uPQ58h7xq9H0jHJ8NvBj4VkQ8nFFeV3HC6D33AZPUuFHuAYrGy5pJ\nwGrW/aPKtRLYsLYh6Tn1ByPi+og4iKJ6/gPggiHi2VZS/b/tJOD+FuJp1qcobid2joh/AN4B1P+m\nD9UlN2RXnYru1a9R3Lb8e609p1fkJgsnjO4yj6L94NOSNpI0XtIHVYx9+EfgFElTJE0APgl8d4ja\nyEhuAV4kaZqk8cDJtQOS1pd0iKRnRcRfgMeBNQ3K+A1F4vkvSc+QtDdwAHB+C/E0a2Pgz8CfJG0D\n/Oeg40sp2npynClpGUUChKKt6LPAOeqxMRpOGD0mItZQ/NHtANwLLAFOBF5HcbuyGvgV8AeKRsFj\nW7zO74FTgJ8CdwFzB53yTmBRqu4fTfE/+OAyngYOTLEtB74KHBoRd7QSU5M+DkwHHgN+TNEAXO9T\nwMdS78qHRijrHOADFLc0h6Z/g89Q1EaOb2vUFeumhOGBWy1IbQcnR8Rr0/YJABHxqUoD6zGSJgOX\nRsSLKw6lNAMDAzF+/Pisc1etWnVDRMwoOaRhuYbRmm1Yt6FuCes2Kppl6bY2jL4bWdcmjf71XFWz\nlnRKMsjhhNGaJRRtFzXPZW3jnFlTuilh+JakNdcDU1PPyPrAwcAlFcdkXaqbbkmcMFqQukyPAa4A\nbgcuiIjbqo2qt0g6D/g1sKOK50mOqDqmsnRTwnAviVmFxo0bFxMm5A38feyxxyrvJXEbhlnFBga6\np6LvhGFWsU653cjhhGFWMScMM8vSSQ2aObrn5qkDSTqy6hh6XT/8jLupl8QJY3R6/pe5A/T8z7ib\nEoZvScwq1inJIEdHJQxJXTcopNti3nXXXasOoSmTJk1ixowZXfUzXrRoEcuXL8/KApLcrWqda/78\n+VWH0PNmzGhubFU31TC6J7WZ9ah2tmFI+qaK5S5+W7fvu5JuTq9Fkm5O+ydLWlV37IyRyncNw6xi\nba5hnAV8mWLGMgAi4m111zqNYka0mrsjYqRZ4//GCcOsYu1MGBFxTZqprNF1BLyVYq2alviWxKxC\nTc64NVHS/LpXs13OewJLI+Kuun1TJN2kYtmKPUcqwDUMs4o10UuyfJRPq86kWPy75kFgUkQ8LGlX\n4AeSXhQRjw9VgBOGWcXGopdExZo6bwL+1q8eEU9RLN1JRNwg6W7g+cCQXWlOGGYVG6Nu1X2BOyKi\nftHuzYFHImKNpOcBU4F7hivEbRhmFWr3rOHDzFR2MOvejgC8Clgg6Rbge8DREfHIcOW7hmFWsTb3\nkswcYv9hDfZdBFzUTPlOGGYV66aRnk4YZhVzwjCzLH74zMya4hqGmWVzwjCzbE4YZpbNCcPMsnTS\nfJ05nDDMKuaEYWbZ3K1qZtlcwzCzLG7DMLOmOGGYWTYnDDPL5oRhZtmcMMwsi59WNbOmuIZhZtmc\nMMwsWzcljO65eTLrQSXMGt5oMeaTJd1ft+jy/nXHTpC0UNKdkl47UvlOGGYVa2fCoFiMeb8G+z8f\nEdPS67J03Z0olh94UfrMVyWtN1zhThhmFWtnwoiIa4Bh1xapcxBwfkQ8FRF/ABYCuw33AScMs4oN\nDAxkvRjdYszHSFqQblk2Sfu2Ae6rO2dJ2jckN3qaVajJ241WF2M+HTgViPT1NOBwoNGFY7iCnDDM\nKlZ2L0lELK271pnApWlzCbBt3anPBR4YrizfkphVrM2Nno3K36pu841ArQflEuBgSc+UNIViMeZ5\nw5XlGoZZxdpZw0iLMe9N0d6xBDgJ2FvSNIrbjUXAUQARcZukC4DfAauB90bEmuHKd8Iwq9gYLMb8\njWHO/wTwidzynTDMKuQZt8ysKd30tGqpkUraLw05XSjp+DKvZdatym70bKfSEkYaYvoV4HXATsDM\nNBTVzOo4YRR2AxZGxD0R8TRwPsVQVDNL2v3wWdnKbMNoNOz0ZYNPSsNbmxniatZTOiUZ5CgzYWQN\nO42I2cBsAEnDDks160VOGIWmh52a9SP3khSuB6ZKmiJpfYrn7i8p8XpmXcdtGElErJZ0DHAFsB7w\nzYi4razrmXWrTkkGOUoduJVm9rmszGuYdTsnDDPL5oRhZlk6qX0ihxOGWcWcMMwsWzd1qw6ZMCT9\niGHm94uIA0uJyKzP9EoN47NjFoVZn+qZNoyI+EXtvaQNgEkRceeYRGXWR7opYYx48yTpAOBm4PK0\nPU2SR2yatUk3jfTMaW05meJR9T8BRMTNwOTyQjLrL+1MGGq8tur/SLojLWT0fUnPTvsnS1qltWuu\nnjFS+TkJY3VEPJYVrZk1rc01jLP4+7VV5wAvjoidgd8DJ9Qdu7tuzdWjRyo8J2H8VtLbgfUkTZX0\nJeBXebGb2XAkNbNU4ogara0aEVdGxOq0eR3Fk+MtyYniWIrVnZ8CzgMeB45r9YJmtq4mahijWVu1\n5nDgJ3XbUyTdJOkXkvYc6cMjDtyKiCeAj0r6TLEZK1oI0syG0MTtRqtrq9au81GKBYvOTbsepOj9\nfFjSrsAPJL0oIh4fqoycXpKXSroVWADcKumWVLiZtcFY9JJImgX8C3BIRARARDwVEQ+n9zcAdwPP\nH66cnKHh3wDeExG/TBfeA/gWsHPr4ZsZjM3ALUn7AR8G9kp3DLX9mwOPRMQaSc+jWFv1nuHKykkY\nK2rJAiAi5krybYlZm7QzYajx2qonAM8E5qRrXZd6RF4FnCJpNbAGODoiHmlYcDLcsyTT09t5kr5G\n0eAZwNuAn4/iezKzOu1MGM2srRoRFwEXNVP+cDWM0wZtn1R/rWYuYmZD64mnVSNin7EMxKwfddKw\n7xxZ82FIej3FWIzxtX0RcUpZQZn1k55KGGl8+YbAPsDXgTcD80qOy6xvdFPCyLl5emVEHAo8GhEf\nB17BugsUmdkodNPTqjm3JKvS1yckbQ08DEwpLySz/tIpySBHTsK4ND0O+z/AjRQ9JF8vNSqzPtFJ\ntYccOc+SnJreXiTpUmC8H3c3a5+e6FaV9KZhjhERF5cTkll/6ZUaxgHDHAvACcOsDXoiYUTEu8Yy\nELN+1HNtGGZWLicMM8vmhGFm2Xq+lwRwL4lZG/RSG0atl2QL4JXAz9L2PhTzYThhmLVBTySMWi9J\nGqy1U0Q8mLa3Ar4yNuGZ9b6eSBh1JteSRbKUESYKNbN8vZYwfi7pCtZO0XcwcHWpUZn1kW5KGCM2\nz0bEMcAZwC7ANGB2RBxbdmBm/SD30fbcpKLGa6tuKmmOpLvS103Sfkn6oqSFKtZdnT50yYXc/pwb\ngR9HxAeAKyRtnPk5MxtBO5dKpPHaqscDV0XEVOCqtA3wOoqlBaYCRwKnj1R4zoxb706FbQpsD2xD\nUeP456zwm7Dddttx0kknjXyitWzePE+WVraVK1c2dX6bZw2/RtLkQbsPolh6AOBsil7OD6f956SF\nja6T9GxJWw1qs1xHTtp6L7A7xZqqRMRdFF2tZtYGYzDj1pa1JJC+1v5+twHuqztvSdo3pJxGz6ci\n4ulawJLG4WUGzNqiyWQwUdL8uu3ZETF7NJdvsG/Yv+2chPELSR8BNpD0auA9wI9aCM7MGhiDxZiX\n1m410jiqZWn/Etadn/e5wAPDFZRzS3I88BBwK3AUcFlEfLT5mM2skTG4JbkEmJXezwJ+WLf/0NRb\n8nLgseHaLyCvhnFsRHwBOLO2Q9L70z4zG6UxWFv108AFko4A7gXekk6/DNgfWAg8AYw4B05OwpgF\nDE4OhzXYZ2ZNktTWp1WHWFsVGvRqpt6R9zZT/nBPq84E3g5MkXRJ3aGNKZYaMLM26KaRnsPVMH4F\nPAhMZN2FmVcAC8oMyqyf9ETCiIjFwGJJhwAPRMSTAJI2oGhNXTQmEZr1uG5KGDk3TxcAf63bXgNc\nWE44Zv2n15ZKHBcRT9c20iCu9UuMyaxvdFIyyJFTw3hI0oG1DUkHAcvLC8msv/RaDeNo4FxJX6EY\nNroEOLTUqMz6SE9MAlwTEXcDL5c0AVBErCg/LLP+0Sm1hxwjpjZJW0r6BnBhRKyQtFMaMWZmo9Tu\nCXTKllMXOgu4Atg6bf8eOK6sgMz6Ta8ljIkR8beu1YhYTdG1amZt0E0JI6fRc6WkzUjPydeeais1\nKrM+0inJIEdOwvggxWOw20u6FtgceHOpUZn1kZ5KGBFxo6S9gB0pZui5MyL+UnpkZn2g3U+rli1n\nEuDxFLNs7UFxW/JLSWfUni0xs9HpqRoGcA7FE6pfStszgW+zdhIOMxuFXksYO0bELnXbV0u6payA\nzPpNNyWMnJunm1LPCACSXgZcW15IZv2j2wZu5dQwXkYxUei9aXsScLukWylm+dq5tOjM+kCnJIMc\nOQlj8LJrZtZGPdVLAkyNiJ/W75A0KyLOLikms77SrhqGpB2B79bteh5wIvBs4N0Uy4UAfCQiLmvl\nGjmp7URJp0vaKD2I9iPggFYuZmbramcbRkTcGRHTImIasCvF0gHfT4c/XzvWarKAvISxF3A3cDMw\nF/i/iPBIT7M2KanR85+Bu9PcvG2TkzA2oWj4vBt4CthO3dRKY9bhmkgYEyXNr3sdOUyxBwPn1W0f\nI2mBpG9K2qTVWHMSxnXATyJiP+ClFI+5u1vVrE2aSBjLI2JG3avhQswq5tw9kLWTdZ8ObA9Mo1g6\n5LRGn8uR0+i5b0TcCxARq4D3SXpVqxc0s7VKGmPxOuDGiFgKUPuarncmcGmrBefUMO6T9A5JJ6YL\nTgL8HIlZmwwMDGS9mjCTutsRFSu217wR+G2rsebUML5KMXnOPwGnUDxXchHF7YmZjVI7axiSNgRe\nDRxVt/u/JU2jeHh00aBjTcka6RkR0yXdBBARj8rrkpi1TTsTRkQ8AWw2aN8721V+TsL4i6T1WDvj\n1uasuxKambWok54TyZGTML5IMfhjC0mfoJht62OlRmXWR3oqYUTEuZJuoBgIIuANEXF76ZGZ9Yme\nShgAEXEHcEfJsZj1pZ5LGGZWjp6b09PMytVNNYzSUlsas75MUsuDRMz6QTfNuFVmXegsPPmO2Yi6\nKWGUdksSEddImlxW+Wa9olOSQY7K2zDSI7pHAmy22WYjnG3WWzqp9pCj8ubZiJhde1x3woQJVYdj\nNuZ8S2Jm2dytambZOqX2kKPMbtXzgF8DO0paIumIsq5l1q3aOQnwWCizl2RmWWWb9ZJOSQY5fEti\nVjEnDDPL5oRhZtmcMMwsi59WNbOmtHkS4EUUE3WvAVZHxAxJm1KsuTqZYhLgt0bEo62U3z2pzaxH\nldCtuk9aQ3VG2j4euCoipgJXpe2WOGGYVWwMxmEcBJyd3p8NvKHVgpwwzCpUwsCtAK6UdIPWrr26\nZUQ8CJC+btFqvG7DMKtYE8lgoqT5dduzG6yvuntEPCBpC2COpLbOxeuEYVaxJnpJlte1SzQUEQ+k\nr8skfR/YDVgqaauIeDAtm7is5Vhb/aCZtUe7bkkkbSRp49p74DUU66heAsxKp80CfthqrK5hmFWo\nzQ+WbQl8P5U3Dvi/iLhc0vXABekB0HuBt7R6AScMs4q1K2FExD3ALg32P0yxENmoOWGYVcxDw80s\nmxOGmWVzwjCzLH74zMya4hqGmWVzwjCzbE4YZpalk2YEz+GEYVYxJwwzy+aEYWbZ3K1qZlnchmFm\nTXHCMLNsThhmls0Jw8yyOWGYWRY3eppZU9ytambZXMMws2zdlDC6py5k1oPaufKZpG0lXS3pdkm3\nSXp/2n+ypPsl3Zxe+7car2sYZhVrYw1jNfAfEXFjWp/kBklz0rHPR8RnR3sBJwyzirVxmYEHgdoa\nqisk3Q5s05bCE9+SmFWsiVuSiZLm172OHKbMycBLgN+kXcdIWiDpm5I2aTVW1zDMKtTkJMAjrq2a\nypwAXAQcFxGPSzodOJViZfdTgdOAw1uJ1wnDrGLt7CWR9AyKZHFuRFwMEBFL646fCVzaavkdlTAW\nL168/PDDD19cdRxNmAgsrzqIHteNP+Ptmjm5XQlDRUHfAG6PiM/V7d8qtW8AvJFigeaWdFTCiIjN\nq46hGZLm51QRrXX98DNuYw1jd+CdwK2Sbk77PgLMlDSN4pZkEXBUqxfoqIRh1o/a2EsyF2hU2GVt\nuQBOGGaV8sNn/WV21QH0gZ7/GXfTw2fdE2kHiogx/WWW9Of0dWtJ3xvh3OMkbdhk+XtL+rsW9KH2\nDzrnMElfbvJ6iyRNHO6csf4ZV6FdQ8PHghNGxSSt1+xnIuKBiHjzCKcdBzSVMKwaThiGpMmS7pB0\ndhph973a//jpf9YTJc0F3iJpe0mXS7pB0i8lvSCdN0XSryVdL+nUQWX/Nr1fT9JnJd2arnOspPcB\nWwNXS7o6nfeaVNaNki5Mg3uQtF+Kcy7wpozvazdJv5J0U/q6Y93hbdP3caekk+o+8w5J89KDT19r\nJUn2qtxk4YTRH3YEZkfEzsDjwHvqjj0ZEXtExPkU9+nHRsSuwIeAr6ZzvgCcHhEvBf44xDWOBKYA\nL0nXOTcivgg8AOwTEfukav/HgH0jYjowH/igpPHAmcABwJ7AczK+pzuAV0XES4ATgU/WHdsNOASY\nRpEIZ0h6IfA2YPeImAasSedY0k0Jw42e5bovIq5N778DvA+oPTH4XfjbMN5XAhfW/VI8M33dHfjX\n9P7bwGcaXGNf4IyIWA0QEY80OOflwE7Ateka6wO/Bl4A/CEi7kqxfIciAQ3nWcDZkqZS9Os/o+7Y\nnIh4OJV1MbAHxROUuwLXp2tvACwb4Rp9pVOSQQ4njHLFMNsr09cB4E/pf9+cMgZT5jlzImLmOjvX\nDuZpxqnA1RHxRhUPOP287lij71fA2RFxQpPX6RvdlDB8S1KuSZJekd7PBOYOPiEiHgf+IOktUAzv\nlbRLOnwtcHB6P1Q1/krgaEnj0uc3TftXABun99cBu0vaIZ2zoaTnU9xeTJG0fV2MI3kWcH96f9ig\nY6+WtKmkDYA3pPivAt4saYtafJKaGjrdy5QePst5dYLOiKJ33Q7MkrQA2BQ4fYjzDgGOkHQLcBtw\nUNr/fuC9kq6n+ENt5OvAvcCC9Pm3p/2zgZ9IujoiHqL44z4vxXId8IKIeJLiFuTHqdEz5zme/wY+\nJelaYHDj5VyKW6ebgYsiYn5E/I6i/eTKdO05wFYZ1+kb3dSGoYhma6SWI1XXL42IF1ccinWw6dOn\nx9y5f1fxbGijjTa6oernatyGYVaxTqk95HDCKElELAJcu7BhddLtRg4nDLOKOWGYWTYnDDPL1ild\npjmcMMwq5DYMM2uKE4aZZeumhOGBW2YVknQ5xczoOZZHxH5lxjMSJwwzy9Y9zbNmVjknDDPL5oRh\nZtmcMMwsmxOGmWVzwjCzbE4YZpbNCcPMsjlhmFm2/wdCEwhCTJPA3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21a313f5f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#assess NB\n",
    "model_assessment(y_test,predicted_class_NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create and fit tree model\n",
    "model_tree=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tree.fit(train_features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run model on test and print metrics\n",
    "predicted_class_tree=model_tree.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[136  66]\n",
      " [ 46  77]]\n",
      "accuracy\n",
      "0.655384615385\n",
      "precision\n",
      "0.538461538462\n",
      "recall\n",
      "0.626016260163\n",
      "f-Score\n",
      "0.578947368421\n",
      "AUC\n",
      "0.649641793448\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAD0CAYAAABuOhhTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21a3141c550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_assessment(y_test,predicted_class_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create and fit SVM model\n",
    "model_svm=SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm.fit(train_features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run model on test and print metrics\n",
    "predicted_class_svm=model_svm.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[202   0]\n",
      " [123   0]]\n",
      "accuracy\n",
      "0.621538461538\n",
      "precision\n",
      "0.0\n",
      "recall\n",
      "0.0\n",
      "f-Score\n",
      "0.0\n",
      "AUC\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iGuest\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\iGuest\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAD3CAYAAADormr9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21a3231a588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_assessment(y_test,predicted_class_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create and fit model\n",
    "model_rf=RandomForestClassifier(n_estimators=20,criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.fit(train_features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run model on test and print metrics\n",
    "predicted_class_rf=model_rf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[182  20]\n",
      " [ 52  71]]\n",
      "accuracy\n",
      "0.778461538462\n",
      "precision\n",
      "0.78021978022\n",
      "recall\n",
      "0.577235772358\n",
      "f-Score\n",
      "0.663551401869\n",
      "AUC\n",
      "0.739112935684\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAD3CAYAAADormr9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWTEHDDMr5oBhZsUcMMys2P8BHpC/xz42wz0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21a2fb7f898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_assessment(y_test,predicted_class_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
